#functions for predicting MIEs with HTTr and refchemDB datasets



# trim_metadata - subsets HTTr data to ensure that chemicals are not over represented in training data sets
#
# Parameters:
#  nested_data (list) = nested list of metadata and gene expression data for processing
#  profile_limit (numeric) = maximum number of profiles allowed for each chemical - if there are more than [profile_limit] profiles for a dtxsid in the input, output will contain no more than [profile_limit] profiles for each chemical
#  seed (numeric) = seed for random selecting profiles for chems with more profiles than trim_profiles
#
# Return Value:
#  (list) = nested list containing filtered metadata and filtered gene expression data

trim_metadata <- function(nested_data,
                          profile_limit= 20,
                          seed = NULL){
  
  #tabulate the chemicals that are overrepresented with respect to their profile number
  overrepresented_chemicals <- data.frame(table(nested_data$metadata$dtxsid))
  overrepresented_chemicals <- overrepresented_chemicals[overrepresented_chemicals$Freq > profile_limit,]
  
  #remove these overrepresented chemicals from the dataset
  reduced_metadata <- setdiff(nested_data$metadata$dtxsid, overrepresented_chemicals$Var1)
  reduced_metadata <- nested_data$metadata[nested_data$metadata$dtxsid %in% reduced_metadata,]
  
  #iterate through overrepresented chemicals, select n profiles, and add them back, n profiles at a time 
  for (i in overrepresented_chemicals$Var1){
    relevant_profiles_2 <- nested_data$metadata[nested_data$metadata$dtxsid == i,]
    set.seed(seed)
    select_2 <- sample(1:nrow(relevant_profiles_2), profile_limit, replace = F)
    relevant_profiles_2 <- relevant_profiles_2[select_2,]
    reduced_metadata <- rbind(reduced_metadata, relevant_profiles_2)
  }
  
  #filter down gene expression data based on the sample ids that remain in the reduced metadata object
  reduced_gene_expression_data <- nested_data$gene_expression_data[row.names(nested_data$gene_expression_data) %in% reduced_metadata$sample_id,]
  reduced_gene_expression_data$sample_id <- row.names(reduced_gene_expression_data)
  
  #ensure metadata and gene expression data have the same order
  reduced_gene_expression_data <- reduced_gene_expression_data[match(reduced_metadata$sample_id, reduced_gene_expression_data$sample_id),]
  
  #remove sample_id column from gene expression data, as we want only predictors in this matrix
  reduced_gene_expression_data$sample_id <- NULL
  reduced_gene_expression_data <- list("metadata" = reduced_metadata, "gene_expression_data" = reduced_gene_expression_data)
  return(reduced_gene_expression_data)
}



# filter_refchemdb - import and filter refchem chemical-target associations from refchemdb (specifically supplementary table 12)
#
# Parameters:
#  refchemdb_path (character) = full system path to refchemdb .xlsx file
#  support_level (integer) = support level filter - refchemdb records with lower support levels will be removed
#
# Return Value:
#  (data.frame)
#  returns a data frame with an additional column called target_mode generated by concatenating the 
#  target and mode fields

filter_refchemdb <- function(refchemdb_path, 
                             support_level = 5){
  require(readxl)
  #read in refchemdb from specific sheet of .xlsx file located at refchemdb_path
  target_annotations <- data.frame(read_excel(refchemdb_path, sheet = "S12 Data"))
  
  #remove entries where mode is unspecified and where support is lower than the specified cutoff
  target_annotations <-target_annotations[target_annotations$mode != "unspecified" & target_annotations$support >= support_level,]
  
  #initialize output dataframe
  output = data.frame()
  
  #iterate through each chemical in RefChemDB by dtxsid
  for (i in unique(target_annotations$dsstox_substance_id)){
    #select rows associated with each chemical
    per_chemical_targets = target_annotations[target_annotations$dsstox_substance_id == i,]
    #iterate though targets associated with this chemical
    for (j in unique(per_chemical_targets$target)){
      #filter the rows down to only those associated with the target
      chem_by_target = per_chemical_targets[per_chemical_targets$target == j,]
      #select the target_mode with the greatest support and add this row to the output - I used "head" instead of "max" here to 
      #make sure that only one record is returned, in case there is the same level of support for multiple targets
      target_max <- head(chem_by_target[order(chem_by_target$support, decreasing = TRUE),],1)
      output = rbind(output, target_max)
    }
  }
  output$target_mode <- paste0(output$target, "_", output$mode)
  return(output)
}



# table_targets - tabulate the number of chemicals associated with each target_mode in refchemdb
#
# Parameters:
#  target_annotations (data.frame) = filtered refchemdb annotations with a target_mode column

# Return Value:
#  (data.frame) = data frame tabulating how many chemicals are available for each target_mode in refchemdb

table_targets <- function(target_annotations){
  require(data.table)
  #coerce to data table to tabulate the number of chemicals available for each target
  target_annotations <- data.table(target_annotations)
  chemical_table <- target_annotations[,.(members = length(dsstox_substance_id)), by=target_mode]
  
  #coerce back to dataframe and order it with the targets with the largest number of chemicals at the top
  chemical_table <- data.frame(chemical_table)
  chemical_table <-chemical_table[order(chemical_table$members, decreasing = TRUE),]
  return(chemical_table)
}



# collapse_refchemdb_targets - imports, filters, and tabulates refchemdb target_modes, and then collapses them based on maximum
# dissimilarity as measured by jaccard index
#
# Parameters:
#  refchemdb_path (character) = full system path to refchem csv file
#  support_levels (vector) = vector of support levels used in iterative binning of refchemDB target_modes
#  min_chemicals (integer) = minimum number of chemicals required in both members of a pair of target_modes to return a jaccard index value
#  cutree_h (numeric) = numeric between 0.0 and 0.1.  This is handed to cutree to determining the extent to which similar target_modes are binned
#  cluster_method (character) = a valid option for "method" for the hclust() function
#
# Return Value:
#  (list) = returns with the following elements:
#  refchem_cleaned_collapsed (data.frame) = altered refchemdb manifest with collapsed target_modes
#  jaccard_matrix (data.frame)
#  groups (data.frame)

collapse_refchemdb_targets <- function(refchemdb_path,
                                       support_levels = c(5),
                                       min_chemicals = 5,
                                       cutree_h = 0.7,
                                       cluster_method= "complete")
{
  require(rlist)
  #require(data.table)
  message("This will probably take some time...")
  message("importing refchem")
  #import and clean a raw refchem file - use the minimum integer from the support level vector as to not throw out
  #entries that need to be considered for the combination step
  refchem_cleaned <- filter_refchemdb(refchemdb_path =  refchemdb_path,
                                      support_level = min(support_levels))
  message("tabulating targets")
  target_table <- table_targets(refchem_cleaned)
  message("calculating jaccard indices")
  #remove targets with fewer chemicals than required by min_chemicals - we have insufficient chemicals to calculate jaccard index for these targets
  target_table <- target_table[target_table$members >= min_chemicals,]
  refchem_cleaned = data.frame(refchem_cleaned)
  #initialize matrix to catch similarity scores
  matrix= data.frame()
  #iterate through each target_mode
  for (i in target_table$target_mode){
    #select only the rows associated with this target
    target_refchem = refchem_cleaned[refchem_cleaned$target_mode == i,]
    temp = c()
    #iterate through each target_mode again 
    for (j in target_table$target_mode){
      #select only the rows associated with this target
      query_refchem = refchem_cleaned[refchem_cleaned$target_mode == j,]
      support_temp = c()
      #iterate through each support level
      for (k in support_levels){
        #filter out records with a support level beneath the cutoff
        temp_target_refchem = target_refchem[target_refchem$support >= k,]
        temp_query_refchem = query_refchem[query_refchem$support >= k,]
        #after filtering, are there at least 10 chemicals in the target and query? If so, calculate the jaccard index and add to the list
        if (length(temp_target_refchem$dsstox_substance_id) >= min_chemicals & length(temp_query_refchem$dsstox_substance_id) >= min_chemicals){
          intersect <- length(intersect(temp_target_refchem$dsstox_substance_id, temp_query_refchem$dsstox_substance_id))
          union <- length(union(temp_target_refchem$dsstox_substance_id, temp_query_refchem$dsstox_substance_id))
          jaccard <- intersect/union
          support_temp <- c(support_temp, jaccard)
        }
      }
      #from the list of jaccard indexes just calculated, take the minimum jaccard index as the representative metric of similarity between those target_modes
      temp = c(temp, min(support_temp))
    }
    #transpose this column into a row
    temp = data.frame(t(temp))
    #assign names to these columns - is this really necessary?
    names(temp) <- target_table$target_mode
    #add the row of indexies to the growing matrix
    matrix = rbind(matrix, temp)
  }
  row.names(matrix) <- target_table$target_mode
  
  #convert similarities into dissimilarities
  neg_matrix = 1-matrix
  #calculate distance between each target_mode
  m_dist <- as.dist(m = data.frame(neg_matrix))
  #cluster the target_modes based on distance
  mhclust <- hclust(m_dist, method = cluster_method)
  
  #export grouping of target_mode labels using cutree
  groups <- data.frame("group" = cutree(mhclust, h = cutree_h))
  groups$name <- rownames(groups)
  
  message("editing chemical manifest")
  #tabulate the number of chemicals in each group
  table = data.frame(table(groups$group))
  
  #at this point we have a dataframe of groupings telling us which MIEs need to be collapsed 
  #iterate through this dataframe by group and generate a new chemical manifest
  for (i in 1:nrow(table)){
    #select the group name
    group = table[i,]$Var1
    #get a list of targets in this group
    targets <- groups[groups$group == group,]
    
    #name each group after its first MIE member - and if there's more than one member, append "_group" to the end
    group_name = targets$name[1]
    if (nrow(targets) > 1){
      group_name <- paste0(group_name, "_group")
    }
    
    #iterate through target names for targets in this group and reassign them to the name of their group
    for (j in targets$name){
      refchem_cleaned[refchem_cleaned$target_mode ==j,]$target_mode <- group_name
      groups[groups$name == j,]$group <- group_name
    }
  }
  #organize this modified chemical manifest as a list
  collapsed_targets <- list("collapsed_targets" = refchem_cleaned, "jaccard_matrix" = matrix, "groups" = groups)
  
  return(collapsed_targets)
}



# get_gene_expression_data - imports gene expression data for training mieml model and trims metadata to mitigate overrepresentation of specific chemicals
#
# Parameters:
#  metadata (data.frame) = data frame of HTTr metadata
#  profile_limit (numeric) = optional max number of gene expression profiles permitted per dtxsid
#  seed (integer) = seed to be set before executing functions that use RNG - for reproducibility
#  gene_expression_data_path (character) = path to gene expression data
#  probe_info_subset (data.frame) = optional dataframe containing probe ids for filtering input data down
#
# Return Value:
#  (list) = returns a list with the following elements:
#  gene_expression_data (data.frame) = data frame of gene expression data
#  metadata (data.frame) = data frame of metadata

get_gene_expression_data <- function(metadata,
                                     profile_limit = NULL,
                                     seed,
                                     gene_expression_data_path, 
                                     probe_info_subset = NULL){
  require(dplyr)
  
  #read gene expression data from disk
  message("- loading gene expression data -\n")
  expression_data <- readRDS(gene_expression_data_path)
  
  #filter expression data to only the samples in metadata and then reorder
  expression_data <- expression_data[as.character(metadata$sample_id)]
  
  #if gene info subset is given, filter the expression data down to just the genes in that dataframe
  if (!is.null(probe_info_subset)){
    expression_data <- expression_data[row.names(expression_data) %in% probe_info_subset$probe_name,]
  }
  
  #transpose gene expression data
  expression_data <- data.frame(t(expression_data))
  
  #combine metadata and gene expression data into a list object
  nested_data <- list("gene_expression_data" = expression_data, "metadata" = metadata)
  
  #if profile limit exists, trim the metadata based on profile limit
  if (!is.null(profile_limit)){
    message("Triming overrepresented chemicals from analysis")
    nested_data <- trim_metadata(nested_data = nested_data,
                                 profile_limit = profile_limit,
                                 seed = seed)
  }
  return(nested_data)
}



# table_profiles - generates a table of HTTr profiles available for training each target_mode model
#
# Parameters:
#  target_table (data.table) = table of tabulated target-modes generated by table_targets()
#  metadata (data.table) = metadata object after filtering HTTr metadata
#  target_annotations (data.table) = cleaned and filtered refchemDB object
#  exemplar_chems (data.frame) = optional dataframe of DTXSIDs corresponding exemplar refchems to exclude from tabulation
#  min_profiles (integer) = minimum number of HTTr profiles required for a target_mode to persist
#  min_chemicals (integer) = minimum number of the set of chemicals associated with HTTr profiles required for a target_mode to persist
#
# Return Value:
#  (data.frame) = data frame of target_modes and their number of associated chemicals and HTTr profiles

table_profiles <- function(target_table, 
                           metadata, 
                           target_annotations,
                           exemplar_chems = NULL,
                           min_profiles = 25, 
                           min_chemicals = 5){
  
  #filter get set of targets with at least (min_chemicals) chemicals
  target_list <- target_table[target_table$members >= min_chemicals,]$target_mode
  
  #initialize dataframe to catch output
  output = data.frame()
  for (temp_target in target_list){
    
    #select chemicals only associated with this target_mode
    temp_refchem_chems = target_annotations[target_annotations$target_mode == temp_target,]
    
    #remove chemicals that show up in the exemplar_chems object
    if (!is.null(exemplar_chems)){
      `%notin%` <- Negate(`%in%`)
      temp_refchem_chems = temp_refchem_chems[temp_refchem_chems$dsstox_substance_id %notin% exemplar_chems$dsstox_substance_id,]
    }
    
    temp_relevant_metadata = metadata[metadata$dtxsid %in% temp_refchem_chems$dsstox_substance_id,]
    output = rbind(data.frame("target_mode" = temp_target, 
                              "n_profiles" = nrow(temp_relevant_metadata),
                              "n_chemicals" = length(unique(temp_relevant_metadata$dtxsid))),
                   output)
  }
  output <-output[order(output$n_profiles, decreasing = TRUE),]
  output <- output[output$n_profiles >= min_profiles &  output$n_chemicals >= min_chemicals,]
  return(output)
}



# get_exemplar_chems - generates a table of chemicals linked to targets to be modeled
#
# Parameters:
#  target_annotations (data.frame) = cleaned and filtered refchemDB object
#  metadata (data.frame) = metadata object after filtering HTTr metadata
#  profile_table (data.frame) = table tabulating the number of chemicals and profiles available for each target
#  min_profiles (integer) = minimum number of HTTr profiles required for a target_mode to persist
#  min_chemicals (integer) = minimum number of the set of chemicals associated with HTTr profiles required for a target_mode to persist
#  target_table (data.frame) = table of tabulated target-modes generated by table_targets()
#
# Return Value:
#  (data.frame) = metadata for exemplar chemicals 

get_exemplar_chems <- function(target_annotations,
                               metadata,
                               profile_table,
                               min_profiles,
                               min_chemicals,
                               target_table){
  #define notin
  `%notin%` <- Negate(`%in%`)
  
  #generate a list of MIEs that have the minimum number of chemicals to train a classifier
  MIEs_with_min_chem_value <- profile_table[profile_table$n_chemicals == min_chemicals,]$target_mode
  
  #use this list of MIEs to generate a list of chemicals that must be retained in the analysis
  chems_must_retain <- target_annotations[target_annotations$target_mode %in% MIEs_with_min_chem_value,]$dsstox_substance_id
  
  #make a temporary profile table object without the MIEs that will be dropped if we exclude even a single chem
  profile_table_short <- profile_table[profile_table$n_chemicals > min_chemicals,]
  
  #sorted from the least to most chemicals- this way we'll try to pick exemplars for data-poor MIEs first
  profile_table_short <- profile_table_short[order(profile_table_short$n_chemicals, decreasing = FALSE),]
  
  #step through the profile table to select a top exemplar reference chemical for each target_mode
  exemplar_chemicals <- data.frame()
  for (i in profile_table_short$target_mode){
    
    #select only refchemdb annotations for target_mode i
    relevant_manifest <- target_annotations[target_annotations$target_mode == i,]
    
    #select only annotations that are not in our in the chems_must_retain object
    relevant_manifest <- relevant_manifest[relevant_manifest$dsstox_substance_id %notin% chems_must_retain,]
    
    #select only the annotations that are also present in metadata
    relevant_manifest <- relevant_manifest[relevant_manifest$dsstox_substance_id %in% metadata$dtxsid,]
    
    #order the annotations by support
    relevant_manifest <- relevant_manifest[order(relevant_manifest$support, decreasing = TRUE),]
    
    #deduplicate the annotations by substance_id - since the table was generated using the "target_mode" field from a collapsed refchemdb database, there are likely to be multiple entries with the same chemical-target_mode linkage, as records are still by target 
    relevant_manifest <- relevant_manifest[!duplicated(relevant_manifest$dsstox_substance_id), ]
    
    #remove from this table any chemicals that are already exemplars and thus are already to be excluded 
    relevant_manifest <- relevant_manifest[relevant_manifest$dsstox_substance_id %notin% exemplar_chemicals$dsstox_substance_id,]
    
    #check if there are at least min_chemicals in this table 
    if (nrow(relevant_manifest) > min_chemicals){
      
      #if there are, we can check the candidate exemplars one by one and see if their removal compromises any training set too much:
      for (j in relevant_manifest$dsstox_substance_id){
        
        #generate a temp profile table with this chemical removed, as well as all the other exemplar chemicals already selected
        profile_table_temp <- table_profiles(target_table = target_table,
                                             metadata = metadata,
                                             target_annotations = target_annotations[target_annotations$dsstox_substance_id != j & target_annotations$dsstox_substance_id %notin% exemplar_chemicals$dsstox_substance_id,],
                                             min_profiles = min_profiles,
                                             min_chemicals =  min_chemicals)
        
        #test if the removal of this chemical would result in the removal of MIEs from the profile table
        if (length(setdiff(profile_table$target_mode, profile_table_temp$target_mode)) == 0){
          
          #if the chemical can be successfully excluded w/o a critical loss of data, add the chemical to the exemplar data and break out of this loop
          exemplar_chemicals <- rbind(relevant_manifest[relevant_manifest$dsstox_substance_id == j,], exemplar_chemicals)
          break()
        }
        
      }
    }
  }
  return(exemplar_chemicals)
}



# hms_span - convert a set of time stamps into a duration formatted in "hh:mm:ss"
#
# Parameters:
#  start (character) = start time from Sys.time()
#  end (character) = end time from Sys.time()
#
# Return Value:
#  (character) = character vector formatted in "hh:mm:ss"

hms_span <- function(start, end){
  dsec <- as.numeric(difftime(end, start, unit = "secs"))
  hours <- floor(dsec / 3600)
  minutes <- floor((dsec - 3600 * hours) / 60)
  seconds <- dsec - 3600*hours - 60*minutes
  paste0(
    sapply(c(hours, minutes, seconds), function(x) {
      formatC(x, width = 2, format = "d", flag = "0")
    }), collapse = ":")
}



# get_data_for_target - format HTTr metadata and profiles for ML 
#
# Parameters:
# seed (numeric) = numeric seed to control RNG for reproducibility 
# generate_null (boolean) = should the chemical-target relationships be shuffled
# target_name (character) = name of target to pull HTTr data for
# exemplar_chems (data.frame) = data frame of appropriately formated exemplar refchems
# target_annotations (data.frame) = data frame of formatted refchemdb
# nested data (list) = list containing metadata and gene expression data
#
# Return Value:
#  (list) = list containing relevant HTTr metadata and gene expression profiles for modeling

get_data_for_target <- function(seed = 123,
                                generate_null = FALSE,
                                target_name,
                                exemplar_chems,
                                target_annotations,
                                nested_data){
  #########################
  require(data.table)
  require(plyr)
  require(dplyr)
  `%notin%` <- Negate(`%in%`)
  
  #generate a list of dtxsids linked to this target in RefChemDB
  target_linked_dtxsids <- target_annotations[target_annotations$target_mode == target_name,]$dsstox_substance_id
  
  #split metadata out of nested data object so that it is easier to work with
  relevant_metadata <- nested_data$metadata
  
  #remove exemplar chemicals from consideration from dtxisd and metadata so it cannot possibly be selected 
  target_linked_dtxsids <- setdiff(target_linked_dtxsids, exemplar_chems$dsstox_substance_id)
  relevant_metadata <- relevant_metadata[relevant_metadata$dtxsid %notin% exemplar_chems$dsstox_substance_id,]
  
  #tabulate the number of profiles available for all chem_ids in the metadata table
  relevant_metadata <- data.table(relevant_metadata)
  full_profile_table <- data.frame(relevant_metadata[,. (profiles = length(sample_id)), by = chem_id])
  relevant_metadata <- data.frame(relevant_metadata)
  
  #select from metadata only the samples associated with dtxsids linked to this target
  target_linked_metadata <- relevant_metadata[relevant_metadata$dtxsid %in% target_linked_dtxsids,]
  
  #if generate_null is TRUE, replace the target_linked_metadata object with similarly structured dummy metadata
  if(generate_null == TRUE){
    
    #coerce target_linked_metadata to data.table
    target_linked_metadata <- data.table(target_linked_metadata)
    
    #tabulate the number of profiles there are available for each chem_id linked to the target
    target_linked_profile_table <- data.frame(target_linked_metadata[,. (profiles = length(sample_id)), by = chem_id])
    
    #coerce metadata linked to this target back to data.frame
    target_linked_metadata <- data.frame(target_linked_metadata)
    
    #initialize a noise_metadata object to catch synthetic metadata
    noise_metadata <- data.frame()
    
    #initialize an eligible null chemical table with a copy of the full_profile_table
    eligible_null_chemicals <- full_profile_table
    
    #iterate through each row of this table, randomly select a chemical with as many profiles, and add it to the noise table
    for (i in 1:nrow(target_linked_profile_table)){
      
      #first restrict available profiles only to chemicals that haven't already been added to the noise_metadata list
      eligible_null_chemicals <- eligible_null_chemicals[eligible_null_chemicals$chem_id %notin% noise_metadata$chem_id,]
      
      #identify the number of profiles this "real" chemical can contribute to training data
      temp_n_profile_contribution = target_linked_profile_table[i,]$profiles
      
      #randomly pick a chemical's metadata for a chemical that has at least as many profiles as the true chemical
      set.seed(seed)
      temp_chem <- sample_n(tbl = eligible_null_chemicals[eligible_null_chemicals$profiles >= temp_n_profile_contribution,], size = 1)
      
      #select the metadata for this chemical
      temp_metadata <- relevant_metadata[relevant_metadata$chem_id == temp_chem$chem_id,]
      
      #trim the metadata for this chemical down to size matched set of metadata
      set.seed(seed)
      temp_metadata <- sample_n(tbl = temp_metadata, size = temp_n_profile_contribution, replace = FALSE)
      
      #add this metadata to output
      noise_metadata <- rbind(noise_metadata, temp_metadata)
    }
    
    #now that we have fully populated the noise metadata object, overwrite target metadata object 
    target_linked_metadata <- noise_metadata
    
    #restrict available inactive data to what chem ids are not in target metadata - doing this at the level of dtxsid and not chem_id
    null_metadata <- relevant_metadata[relevant_metadata$dtxsid %notin% target_linked_metadata$dtxsid,]
  }
  
  #if generate_null is false, we need to simply select null metadata as all the available metadata not linked to the target
  if (generate_null == FALSE){
    #select HTTr data not associated with this target and that are associated with some target in refchemDB
    null_metadata <- relevant_metadata[relevant_metadata$dtxsid %notin% target_linked_dtxsids,]
  }
  
  #assign label to target and null sets
  target_linked_metadata$label <- "target"
  null_metadata$label <- "null"
  
  #if there are more profiles in the target dataset than null, trim the target to be equal in size - this is almost never true
  if (nrow(target_linked_metadata) > nrow(null_metadata)){
    set.seed(seed)
    rows_to_keep <-sample(1:nrow(target_linked_metadata), nrow(null_metadata), replace = F)
    target_linked_metadata <- target_linked_metadata[rows_to_keep,]
  }
  
  #trim null dataset (randomly) to be the same size as the target to ballance class labels
  set.seed(seed)
  rows_to_keep <-sample(1:nrow(null_metadata), nrow(target_linked_metadata), replace = F)
  null_metadata <- null_metadata[rows_to_keep,]
  
  #generate hold out target metadata data
  num_holdout <- length(target_linked_metadata$sample_id) * 0.2
  set.seed(seed)
  target_metadata_holdout <- sample(1:length(target_linked_metadata$sample_id), num_holdout, replace = F)
  target_metadata_holdout <- target_linked_metadata[target_metadata_holdout,]
  
  set.seed(seed)
  null_metadata_holdout <- sample(1:length(null_metadata$sample_id), num_holdout, replace = F)
  null_metadata_holdout <- null_metadata[null_metadata_holdout,]
  
  #remove holdout samples from target and null objects
  target_metadata_train <- target_linked_metadata[target_linked_metadata$sample_id %notin% target_metadata_holdout$sample_id,]
  
  null_metadata_train <- null_metadata[null_metadata$sample_id %notin% null_metadata_holdout$sample_id,]
  
  #concatenate target and null datasets
  metadata_train <- data.frame(rbind(target_metadata_train, null_metadata_train), "use" = "train")
  metadata_holdout <- data.frame(rbind(target_metadata_holdout, null_metadata_holdout), "use" = "holdout")
  
  #concatenate training, holdout, exemplar, and null pred metadata
  metadata <- data.frame(rbind(metadata_train,
                               metadata_holdout))
  
  gene_expression_data <- nested_data$gene_expression_data  
  gene_expression_data$sample_id <- row.names(gene_expression_data)
  
  #subset HTTr profiles down to those that are included in metadata
  gene_expression_data <- gene_expression_data[gene_expression_data$sample_id %in% metadata$sample_id,]
  
  #reorder the cmap matrix so that profiles match up with the labels in metadata
  gene_expression_data <- gene_expression_data[match(metadata$sample_id, gene_expression_data$sample_id),]
  
  gene_expression_data$use <- metadata$use
  gene_expression_data$label <- metadata$label
  
  return(list("gene_expression_data" = gene_expression_data, "metadata" = metadata))
}



# format_HTTr_for_ML - simple function for partitioning gene expression data into training and holdout datasets
#
# Parameters:
# gene_expression_data (dataframe) = data frame of HTTr gene expression profiles
# use_field (character) = filter for use_field column for subsetting HTTr matrix
# label_field (character) = filter for label_field column for subsetting HTTr matrix
#
# Return Value:
#  (dataframe) = dataframe containing only the relevant HTTr profiles for modeling

format_HTTr_for_ML <- function(gene_expression_data,
                               use_field = NULL,
                               label_field = NULL){
  if (!is.null(use_field)){
    gene_expression_data = gene_expression_data[gene_expression_data$use == use_field,]
  }
  if (!is.null(label_field)){
    gene_expression_data = gene_expression_data[gene_expression_data$label == label_field,]
  }
  gene_expression_data$use <- NULL
  gene_expression_data$label <- NULL
  gene_expression_data$sample_id <- NULL
  return(gene_expression_data)
}



# model_target - generate a predictive model for a single target_mode using refchemDB labels and HTTr gene expression
#
# Parameters:
#  target (character) = name of the target_mode to for which a model should be trained
#  expanded_grid (list) = optional named list of model hyperparameters to override caret defaults
#  allowParallel_training (boolean) = should hyperparameter tuning be run with parallelization?
#  support_level (integer) = minimal support level used to filter refchemDB - this isn't explicitly used other than to record this parameter in output
#  generate_null (boolean) = should the profiles in the MIE active set be randomly selected to generate a null model?
#  model_names (vector) = vector of characters corresponding to model types recognized by caret 
#  nested data (list) = list containing metadata and gene expression data
#  target_annotations (data.table) = cleaned and filtered refchemDB object
#  return_model (boolean) = whether to export full model information along with result summary
#  seed (integer) = seed for controling RNG for reproducibility
#  exemplar_chems (data.frame) = table of reference chemicals to exclude from training and to predict on
#  save_model (boolean) = should the full model be saved to disk
#  output_dir (character) = full output path to where model should be saved - only relevant if save_model is TRUE
#
# Return Value:
#  (list) = returns a list containing two elements: a "results" dataframe that tabulates results metrics for each model and a 
#  "model_objects" list which contains more detailed model information for each model trained

model_target <- function(target_name, 
                         expanded_grid = NULL,
                         allowParallel_training = FALSE,
                         support_level = 5,
                         generate_null = FALSE,
                         model_names, 
                         nested_data,
                         target_annotations, 
                         return_model = FALSE, 
                         seed = 123, 
                         exemplar_chems,
                         save_model = FALSE,
                         output_dir = NULL){
  #require(data.table)
  require(caret)
  require(rlist)
  require(doParallel)
  
  #intended for when this function is called directly and not by other functions - allows the analysis to proceed using multiple cores
  if (allowParallel_training == TRUE){
    registerDoParallel(cores=floor(sqrt(detectCores())))
  }
  
  op <- options(digits.secs = 2)
  
  #initialize dataframe to catch results
  results_summary = data.frame()
  model_objects = list()
  
  #pull relevant HTTr metadata and profiles for this target
  target_specific_data <- get_data_for_target(seed = seed,
                                              target_name = target_name,
                                              generate_null = generate_null,
                                              exemplar_chems = exemplar_chems,
                                              nested_data = nested_data,
                                              target_annotations = target_annotations)
  
  #intialize train.control for 5 fold cross validation
  train.control <- trainControl(classProbs =  TRUE,method = "cv", number = 5, verboseIter = FALSE, returnData = TRUE, allowParallel = allowParallel_training)
  
  training_data <- format_HTTr_for_ML(gene_expression_data = target_specific_data$gene_expression_data, use_field = "train")
  
  #if deviating from the default caret hyperparameter tuning grid, convert the percentage values in the tuning grid for rf into integers given the number of training features
  expanded_grid_copy <- expanded_grid
  if (!is.null(expanded_grid_copy)){
    rf_params <- expanded_grid_copy[["rf"]]
    for (i in 1:nrow(rf_params)){
      rf_params[i,] <- round(rf_params[i,]*ncol(training_data))
    }
    expanded_grid_copy[["rf"]] <- rf_params
  }
  
  target_results=data.frame()
  for (model_name in model_names){
    
    loop_start_time <- Sys.time()
    
    message(paste0("- Modeling ", target_name, " with ", model_name, " -\n"))
    
    standardized_model <- train(x = training_data, 
                                y = as.factor(target_specific_data$metadata[target_specific_data$metadata$use == "train",]$label), 
                                method = model_name ,trControl = train.control, tuneGrid = expanded_grid_copy[[model_name]])
    
    message("- finished training, generating predictions for holdout data -\n")
    holdout_predictions <- predict.train(standardized_model, newdata = format_HTTr_for_ML(gene_expression_data = target_specific_data$gene_expression_data,
                                                                                          use_field = "holdout"))
    message("- generating confusion matrix for holdout data -\n")
    holdout_results <- confusionMatrix(data = holdout_predictions,
                                       reference = as.factor(target_specific_data$metadata[target_specific_data$metadata$use == "holdout",]$label), mode = "everything")
    
    message("- finished confusion matrix, caluclating probabilities -\n")
    holdout_predictions_target <- predict.train(standardized_model,
                                                newdata = format_HTTr_for_ML(gene_expression_data = target_specific_data$gene_expression_data,
                                                                             use_field = "holdout",
                                                                             label_field = "target"), type = "prob")
    
    holdout_predictions_null <- predict.train(standardized_model,
                                              newdata = format_HTTr_for_ML(gene_expression_data = target_specific_data$gene_expression_data,
                                                                           use_field = "holdout",
                                                                           label_field = "null"), type = "prob")
    
    holdout_predictions_target$label <- "target"
    holdout_predictions_target$use <- "holdout"
    
    holdout_predictions_null$label <- "null"
    holdout_predictions_null$use <- "holdout"
    
    predictions <- data.frame(rbind(holdout_predictions_target,
                                    holdout_predictions_null))
    
    #add predicted label for AUROC calculations
    predictions$pred <- as.factor(ifelse(predictions$target > 0.5, "target", "null"))
    predictions$pred <- factor(predictions$pred, levels = c("null", "target"))
    predictions$obs <- as.factor(predictions$label)
    
    holdout_AUROC <- twoClassSummary(data = predictions[predictions$use == "holdout",], lev = levels(predictions[predictions$use == "holdout",]$pred))
    
    predictions$pred <- NULL
    predictions$obs <- NULL
    
    message("- finished caluclating continuous probabilities -\n")
    
    #add to this object, other results objects
    standardized_model$holdout_confusion_matrix <- holdout_results
    standardized_model$pred <- predictions
    standardized_model$metadata <- target_specific_data$metadata
    
    loop_end_time <- Sys.time()
    time_elapsed <- hms_span(loop_start_time,loop_end_time)
    
    standardized_results =data.frame("target_name" = target_name,
                                     "model_name" = model_name, 
                                     "internal_accuracy" = max(standardized_model$results$Accuracy),
                                     "holdout_accuracy" = holdout_results$overall[1],
                                     "holdout_auroc" = holdout_AUROC[1],
                                     "target_members" = nrow(target_specific_data$metadata[target_specific_data$metadata$label == "target",]), 
                                     "holdout_members" = nrow(target_specific_data$metadata[target_specific_data$metadata$use == "holdout",]), 
                                     "time elapsed" = time_elapsed,
                                     "support_level" = support_level)
    
    if (save_model == TRUE){
      temp = list("summary" = standardized_results,"model" = standardized_model)
      message(paste0("- saving file ",output_dir, "/", target_name,"/", target_name,"_", model_name,".rds -\n"))
      dir.create(paste0(output_dir, "/",target_name))
      saveRDS(temp, file = paste0(output_dir, "/", target_name,"/", target_name,"_", model_name,".rds"))
    }
    
    #for SVMs this component of the model must be saved - if not, it can be removed to save disk space
    if (!grepl(pattern = "svm", x = model_name)){
      standardized_model$finalModel <- NULL
    }
    
    standardized_model$trainingData <- NULL   
    
    results_summary = rbind(results_summary, standardized_results)
    if (return_model == TRUE){
      model_objects <- list.append(model_objects, "x" = standardized_model)
      names(model_objects)[length(model_objects)] <- paste0(target_name, "_", model_name)
    }
  }
  
  if (return_model == TRUE){
    expanded_result = list("results_summary" = results_summary, "model_objects" = model_objects)
    return(expanded_result)
  }
  
  if (return_model == FALSE){
    return(results_summary)
  }
  
}


# generate_null_models - run permutational models as a null control
#
# Parameters:
#  target_name (character) = name of the target_mode to for which a model should be trained
#  expanded_grid (list) = optional named list of model hyperparameters to override caret defaults
#  allowParallel_training (boolean) = should hyperparameter tuning be run with parallelization?
#  null_workers (integer) = how many cores should be used in parallelization of null classifier training?
#  seed (integer) = seed for controling RNG for reproducibility
#  n_nulls (integer) = how many null classifiers should be trained
#  model_names (vector) = vector of characters corresponding to model types recognized by caret 
#  support_level (integer) = minimal support level used to filter refchemDB - this isn't explicitly used other than to record this parameter in output
#  nested data (list) = list containing metadata and gene expression data
#  target_annotations (data.table) = cleaned and filtered refchemDB object
#  exemplar_chems (data.frame) = table of reference chemicals to exclude from training and to predict on
#  standard_model_summary (data.frame) = data frame containing model performance metrics from the original (non-null) model
#  critical_perm_metrics (vector) = character vector describing the metrics that will be used for empirical significance thresholding
#  critical_perm_thresholds (vector) = vector of values between 0 and 1 that describe the cutoffs will corespond to the metrics declared in critical_perm_metrics

# Return Value:
#  (list) = returns a list containing two elements: a "results" dataframe that tabulates results metrics for each model and a 
#  "model_objects" list which contains more detailed model information for each model trained

generate_null_models <- function(target_name,
                                 expanded_grid = NULL,
                                 allowParallel_training = FALSE,
                                 null_workers = 1,
                                 seed = 123,
                                 n_nulls = 200,
                                 model_names,
                                 support_level = 3,
                                 nested_data,
                                 target_annotations,
                                 exemplar_chems,
                                 standard_model_summary = NULL,
                                 critical_perm_metrics = c("internal_accuracy", "holdout_accuracy"),
                                 critical_perm_thresholds = c(0.1, 0.1))
{
  require(parallel)
  require(foreach)
  require(doParallel)
  require(rlist)
  require(plyr)
  require(purrr)
  registerDoParallel(cores=null_workers)
  results = list()
  
  #create a vector to help run n_nulls in batches of 50
  batcher <- 1:ceiling(n_nulls/50)
  
  #iterate through each batch number
  for (batch in batcher){
    
    #if there's fewer than 50 iterations to begin with, there will be only one batch with the batch size = permutation number
    if (n_nulls < 50){
      batch_size = n_nulls
    }
    
    #if there 50 or more n_nulls total and there's at least 50 n_nulls needed, run a batch of 50
    if (n_nulls >= 50 & ((n_nulls / (batch*50)) >= 1)){
      batch_size = 50
    }
    
    #if there 50 or more n_nulls total and there's at fewer than 50 perms remaining, run a batch size equal to the remainder
    if (n_nulls >= 50 & ((n_nulls / (batch*50)) < 1)){
      batch_size = n_nulls - ((batch - 1) * 50)
    }
    
    #when over 50 n_nulls are present in the result files and a standard model summary object is present, begin filtering model_names by inspecting performance of null classifiers
    if (length(results) >= 50 & !is.null(standard_model_summary)){
      current_perm_data <- flatten(results)
      current_perm_data <- current_perm_data[names(current_perm_data) == "results_summary"]
      current_perm_data <- as.data.frame(do.call(rbind, current_perm_data))
      for (model in model_names){
        relevant_summary_data <- standard_model_summary[standard_model_summary$model_name == model,]
        relevant_perm_data <- current_perm_data[current_perm_data$model_name == model,]
        #if a model has already failed by critical values, stop training permuted models for it by removing the name from model names
        for (k in 1:length(critical_perm_metrics)){
          # if (nrow(relevant_perm_data[relevant_perm_data$internal_accuracy > relevant_summary_data$internal_accuracy,]) > (n_nulls * 0.05)){
          #   model_names <- model_names[! model_names %in% model]
          if (nrow(relevant_perm_data[relevant_perm_data[critical_perm_metrics[k]] > as.numeric(relevant_summary_data[critical_perm_metrics[k]]),]) > (n_nulls * critical_perm_thresholds[k])){
            model_names <- model_names[! model_names %in% model]
          }
        }
      }
    }
    
    results_temp <- list()
    results_temp <- foreach(i=1:batch_size, .combine = 'list.append', .init = list()) %dopar% {
      seed_counter <- seed + i + ((batch - 1) * 50)
      
      message(paste0("- Generating null model number ",i," with seed ", seed_counter, " -\n"))
      
      if (length(model_names) > 0){
        return(model_target(target_name= target_name, 
                            expanded_grid = expanded_grid,
                            allowParallel_training = allowParallel_training,
                            model_names = model_names, 
                            generate_null = TRUE,
                            support_level = support_level,
                            nested_data = nested_data,
                            target_annotations = target_annotations,
                            return_model = TRUE,
                            seed = seed_counter,
                            exemplar_chems = exemplar_chems,
                            save_model = FALSE)
        )
        
      }
    }
    if (length(model_names) > 0){
      results <- c(results, results_temp)
    }
  }
  
  #trim result output to just the necessary info
  summary_output = data.frame()
  metadata_catcher = list()
  for (i in 1:length(results)){
    
    temp <-  data.frame("model_name" = results[[i]]$results_summary$model_name,
                        "iteration_number" = i,
                        "internal_accuracy" = results[[i]]$results_summary$internal_accuracy,
                        "holdout_accuracy" = results[[i]]$results_summary$holdout_accuracy,
                        "holdout_auroc" = results[[i]]$results_summary$holdout_auroc)
    
    param_catcher = data.frame()
    for (j in 1:nrow(temp)){
      temp_name <- paste0(target_name, "_", temp$model_name[j])
      params <- results[[i]]$model_objects[[temp_name]]$bestTune
      param_catcher <- rbind.fill(param_catcher, params)
    }
    param_catcher$test <- NULL
    temp <- cbind(temp, param_catcher)
    
    summary_output <- rbind.fill(summary_output, temp)
    
    
    metadata_catcher <- list.append(metadata_catcher, 
                                    list("iteration_number" = i,
                                         "metadata" = results[[i]]$model_objects[[1]]$metadata))
    
  }
  return(list("summary_output" = summary_output, "metadata" = metadata_catcher))
}



# empirical_significance_test - run an empirical significance test
#
# Parameters:
#  target_name (character) = name of the target_mode to for which a model should be trained
#  expanded_grid (list) = optional named list of model hyperparameters to override caret defaults
#  model_names (vector) = vector of characters corresponding to model types recognized by caret 
#  seed (integer) = seed for controling RNG for reproducibility
#  support_level (integer) = minimal support level used to filter refchemDB - this isn't explicitly used other than to record this parameter in output
#  nested data (list) = list containing metadata and gene expression data
#  target_annotations (data.table) = cleaned and filtered refchemDB object
#  exemplar_chems (data.frame) = table of reference chemicals to exclude from training and to predict on
#  n_nulls (integer) = how many null classifiers should be trained
#  null_workers (integer) = how many cores should be used in parallelization of null classifier training?

# Return Value:
#  (list) = returns a list containing two elements: a "results" dataframe that tabulates results metrics for each model and a 
#  "model_objects" list which contains more detailed model information for each model trained

empirical_significance_test <- function(target_name, 
                                        expanded_grid = NULL,
                                        model_names, 
                                        seed = 123,
                                        support_level = 5,
                                        nested_data,
                                        target_annotations,
                                        exemplar_chems,
                                        n_nulls = 10, 
                                        null_workers = 2){
  
  message(paste0("- Generating standard model -\n"))
  
  standard_results <-  model_target(target_name = target_name, 
                                    expanded_grid = expanded_grid,
                                    allowParallel_training = TRUE, #this is hard-coded to true, as this function is called by no others and this is not run in parallel
                                    model_names = model_names,
                                    generate_null = FALSE,
                                    support_level = support_level,
                                    nested_data = nested_data,
                                    target_annotations = target_annotations, 
                                    return_model = TRUE, 
                                    seed = seed,
                                    exemplar_chems = exemplar_chems,
                                    save_model = FALSE)
  
  
  message(paste0("- Generating permuted models -\n"))
  
  
  permuted_results <- generate_null_models(target_name= target_name, 
                                           expanded_grid = expanded_grid,
                                           allowParallel_training = FALSE, #this is hard-coded to false - increasing CPU utilization by setting null_workers allows for precise control
                                           null_workers = null_workers,
                                           model_names = model_names, 
                                           seed = seed,
                                           support_level = support_level,
                                           nested_data = nested_data,
                                           target_annotations = target_annotations,
                                           exemplar_chems = exemplar_chems,
                                           n_nulls = n_nulls)
  
  catcher = data.frame()
  
  for (i in unique(permuted_results$summary_output$model_name)){
    
    filtered_permutation_summary = permuted_results$summary_output[permuted_results$summary_output$model_name == i,]
    filtered_standard_summary = standard_results$results_summary[standard_results$results_summary$model_name == i,]
    
    temp <- data.frame("model_name" = i,
                       "internal_accuracy" = filtered_standard_summary$internal_accuracy,
                       "holdout_accuracy" = filtered_standard_summary$holdout_accuracy,
                       "holdout_auroc" = filtered_standard_summary$holdout_auroc,
                       "mean_permuted_internal_accuracy" = mean(filtered_permutation_summary$internal_accuracy),
                       "mean_permuted_holdout_accuracy" = mean(filtered_permutation_summary$holdout_accuracy),
                       "int_acc_emp_pval" = nrow(filtered_permutation_summary[filtered_permutation_summary$internal_accuracy >= filtered_standard_summary$internal_accuracy,])/nrow(filtered_permutation_summary),
                       "hold_acc_emp_pval" = nrow(filtered_permutation_summary[filtered_permutation_summary$holdout_accuracy >= filtered_standard_summary$holdout_accuracy,])/nrow(filtered_permutation_summary),
                       "hold_auroc_emp_pval" = nrow(filtered_permutation_summary[filtered_permutation_summary$holdout_auroc >= filtered_standard_summary$holdout_auroc,])/nrow(filtered_permutation_summary))
    
    catcher = rbind(catcher, temp)
  }
  
  return(list("permutation_summary" = catcher,
              "permutation_source_data" = permuted_results))
  
}



# model_targets - generate predictive models for a multiple target_modes using refchemDB labels and HTTr gene expression
#  this is mainly a wrapper function for model_target which iterates through column of profile_table and runs model_targets with parallelization
#
# Parameters:
#  profile_table (data.frame) = table from table_profiles() to iterate through for target_mode selection
#  expanded_grid (list) = optional named list of model hyperparameters to override caret defaults
#  allowParallel_training (boolean) = should hyperparameter tuning be run with parallelization?
#  target_workers (integer) = number of MIEs for which models are generated simultaneously - strongly recommend keeping this at 1 if training null classifiers
#  null_workers (integer) = how many cores should be used in parallelization of null classifier training?
#  n_nulls (integer) = how many null classifiers should be trained
#  support_level (integer) = minimal support level used to filter refchemDB - this isn't explicitly used other than to record this parameter in output
#  model_names (vector) = vector of characters corresponding to model types recognized by caret 
#  nested data (list) = list containing metadata and gene expression data
#  target_annotations (data.table) = cleaned and filtered refchemDB object
#  seed (integer) = seed for controling RNG for reproducibility
#  exemplar_chems (data.frame) = table of reference chemicals to exclude from training
#  save_model (boolean) = should model be saved to disk?
#  output_dir (character) = full path to where models should be saved - only relevant if save_model is set to TRUE
#  focused_analysis_path (character) = full path to .rds file containing a dataframe of MIEs and classifier names to focus analysis on - useful if analysis was halted prematurely and needs to be restarted
#  critical_perm_metrics (vector) = character vector describing the metrics that will be used for empirical significance thresholding
#  critical_perm_thresholds (vector) = vector of values between 0 and 1 that describe the cutoffs will correspond to the metrics declared in critical_perm_metrics
#
# Return Value:
#  (list) = returns a list of lists.  Each top level element represents a result from a single target_mode
#   These elements are lists of two elements: a "results" dataframe that tabulates results metrics for each model and a 
#  "model_objects" list which contains more detailed model information for each model trained

model_targets <- function(profile_table, 
                          expanded_grid = NULL,
                          allowParallel_training = FALSE,
                          target_workers = 1,
                          null_workers = 1,
                          n_nulls = 0,
                          support_level,
                          model_names, 
                          nested_data,
                          target_annotations, 
                          seed = 123, 
                          exemplar_chems,
                          save_model = FALSE,
                          output_dir = NULL,
                          focused_analysis_path = NULL,
                          critical_perm_metrics = NULL,
                          critical_perm_thresholds = NULL){
  require(parallel)
  require(foreach)
  require(doParallel)
  require(rlist)
  registerDoParallel(cores=target_workers)
  message(paste0("- running model_targets with ",getDoParWorkers(), " parallel MIE workers -"))
  results = list()
  if (!is.null(focused_analysis_path)){
    message("- reading in file for focused analysis -\n")
    focused_analysis <- readRDS(focused_analysis_path)
    profile_table <- profile_table[profile_table$target_mode %in% focused_analysis$target_name,]
    message(paste0("- focusing analysis on ", nrow(profile_table), " MIEs -\n"))
  }
  results <- foreach(i=profile_table$target_mode, .combine = 'list.append', .init = list()) %dopar% {
    if (!is.null(focused_analysis_path)){
      per_target <- focused_analysis[focused_analysis$target_name == i,]
      model_names <- intersect(model_names, per_target$model_name)
    }
    message(paste0("- processing MIE number ", which(profile_table$target_mode == i)," of ", length(profile_table$target_mode)), " -\n")
    model_object <- model_target(target_name = i, 
                                 expanded_grid = expanded_grid,
                                 allowParallel_training = allowParallel_training,
                                 model_names = model_names,
                                 generate_null = FALSE,
                                 support_level = support_level,
                                 nested_data = nested_data,
                                 target_annotations = target_annotations, 
                                 return_model = TRUE, 
                                 seed = seed,
                                 exemplar_chems = exemplar_chems,
                                 save_model = save_model,
                                 output_dir = output_dir)
    
    if(n_nulls > 0){
      
      message(paste0("- Running ", n_nulls, " nulls of ", i, " with ", length(model_names), " algorithms -\n"))
      
      permuted_results <- generate_null_models(target_name = i,
                                               expanded_grid = expanded_grid,
                                               null_workers = null_workers,
                                               allowParallel_training = FALSE, #hard coded to false, use permutation workers to better control parallelization
                                               seed = seed,
                                               n_nulls = n_nulls,
                                               model_names = model_names,
                                               support_level = support_level,
                                               nested_data = nested_data,
                                               target_annotations = target_annotations,
                                               exemplar_chems = exemplar_chems,
                                               standard_model_summary = model_object$results_summary,
                                               critical_perm_metrics = critical_perm_metrics,
                                               critical_perm_thresholds = critical_perm_thresholds)
      
      catcher = data.frame()
      
      for (j in unique(permuted_results$summary_output$model_name)){
        
        filtered_permutation_summary = permuted_results$summary_output[permuted_results$summary_output$model_name == j,]
        filtered_standard_summary = model_object$results_summary[model_object$results_summary$model_name == j,]
        
        temp <- data.frame("model_name" = j,
                           "internal_accuracy" = filtered_standard_summary$internal_accuracy,
                           "holdout_accuracy" = filtered_standard_summary$holdout_accuracy,
                           "holdout_auroc" = filtered_standard_summary$holdout_auroc,
                           "mean_permuted_internal_accuracy" = mean(filtered_permutation_summary$internal_accuracy),
                           "mean_permuted_holdout_accuracy" = mean(filtered_permutation_summary$holdout_accuracy),
                           "mean_permuted_holdout_auroc" = mean(filtered_permutation_summary$holdout_auroc),
                           "int_acc_emp_pval" = nrow(filtered_permutation_summary[filtered_permutation_summary$internal_accuracy >= filtered_standard_summary$internal_accuracy,])/nrow(filtered_permutation_summary),
                           "hold_acc_emp_pval" = nrow(filtered_permutation_summary[filtered_permutation_summary$holdout_accuracy >= filtered_standard_summary$holdout_accuracy,])/nrow(filtered_permutation_summary),
                           "hold_auroc_emp_pval" = nrow(filtered_permutation_summary[filtered_permutation_summary$holdout_auroc >= filtered_standard_summary$holdout_auroc,])/nrow(filtered_permutation_summary))
        
        catcher = rbind(catcher, temp)
      }
      
      # model_object$permutation_data = list("summary" = catcher,
      #             "source_data" = permuted_results)
      if(save_model == TRUE){
        saveRDS(object =  list("permutation_summary" = catcher,
                               "permutation_source_data" = permuted_results),
                file = paste0(output_dir, "/", i, "/", i, "_permutation_results.rds"))
      } 
    }  
    model_object
  } 
  names(results) <- profile_table$target_mode
  return(results)
}



# ml_job - generate predictive models for a multiple target_modes using refchemDB labels and HTTr gene expression
#  this is a wrapper function around several lower-level functions which does target-chemical tabulation, filtering, and modeling
#  all in one step
#
# Parameters:
#  expanded_grid_path (character) = full path to .rds file containing named list of model hyperparameters to override caret defaults
#  allowParallel_training (boolean) = should hyperparameter tuning be run with parallelization?
#  refchemdb_path (character) = full path to RefchemDB file
#  n_nulls (integer) = how many null classifiers should be trained
#  support_level (integer) = minimal support level used to filter refchemDB - this isn't explicitly used other than to record this parameter in output
#  min_chemicals (integer) = minimum number of the set of chemicals associated with HTTr profiles required for a target_mode to persist
#  min_profiles (integer) = minimum number of HTTr profiles required for a target_mode to persist
#  target_workers (integer) = number of MIEs for which models are generated simultaneously - strongly recommend keeping this at 1 if training null classifiers
#  null_workers (integer) = how many cores should be used in parallelization of null classifier training?
#  seed (integer) = seed for controling RNG for reproducibility
#  cutree_h (numeric) = numeric between 0.0 and 0.1.  This is handed to cutree to determining the extent to which similar target_modes are binned
#  cluster_method (character) = a valid option for "method" for the hclust() function
#  save_model (boolean) = should model be saved to disk?
#  output_dir (character) = full path to where models should be saved - only relevant if save_model is set to TRUE
#  local_r_package_path (character) = full path to location where r packages are installed that may be required for this analysis
#  gene_expression_data_path (character) = path to gene expression data
#  metadata_path (character) = full path to file containing metadata for httr study
#  tpod_estimate_path (character) = full path to file containing transcriptomic points of departure to be used for bioactivity filtering
#  previous_analysis_path (character) = full path to previous ml_job outputs to scan - useful for starting an analysis where the previous one stopped 
#  focused_analysis_path (character) = full path to .rds file containing a dataframe of MIEs and classifier names to focus analysis on - useful if analysis was halted prematurely and needs to be restarted
#  profile_limit (numeric) = optional max number of gene expression profiles permitted per dtxsid
#  critical_perm_metrics (vector) = character vector describing the metrics that will be used for empirical significance thresholding
#  critical_perm_thresholds (vector) = vector of values between 0 and 1 that describe the cutoffs will correspond to the metrics declared in critical_perm_metrics
#  one_target_to_chems (boolean) = should refchemdb annotations be filtered such that each chemical is linked to only one target
#  probe_info_subset_path (character) = optional full path to file containing probe ids to subset gene expression data down to
#
# Return Value:
#  (list) = returns a list of lists.  Each top level element represents a result from a single target_mode
#   These elements are lists of two elements: a "results" dataframe that tabulates results metrics for each model and a 
#  "model_objects" list which contains more detailed model information for each model trained

ml_job <- function(expanded_grid_path = NULL,
                   allowParallel_training = TRUE,
                   refchemdb_path,
                   n_nulls = 200,
                   support_level = 3,
                   min_chemicals = 5, 
                   min_profiles = 25, 
                   model_names = c("svmLinear", "svmRadial", "svmPoly", "knn", "rf", "mlpML"), 
                   target_workers = 1,
                   null_workers = 25,
                   seed = 123,
                   cutree_h = 0.7,
                   cluster_method = "complete",
                   save_model = FALSE,
                   output_dir = NULL,
                   reverse_MIE_training_order = FALSE,
                   local_r_package_path = NULL,
                   gene_expression_data_path,
                   metadata_path,
                   tpod_estimate_path,
                   previous_analysis_path = NULL,
                   focused_analysis_path = NULL,
                   profile_limit = 25,
                   critical_perm_metrics = c("internal_accuracy", "holdout_accuracy"),
                   critical_perm_thresholds = c(0.1, 0.1),
                   one_target_to_chems = TRUE,
                   probe_info_subset_path = NULL){
  require(rlist)
  `%notin%` <- Negate(`%in%`)
  
  if(!is.null(probe_info_subset_path)){
    library(readxl)
    probe_info_subset <- read_xlsx(path = probe_info_subset_path)
    names(probe_info_subset)[1] <- "probe_name"
  } else {
    probe_info_subset <- NULL
  }
  
  #check to see if local r library location is specified - if so, add it to libPaths
  if (!is.null(local_r_package_path)){
    .libPaths(new = c(.libPaths(), local_r_package_path))
  }
  
  if (!is.null(expanded_grid_path)){
    message("- importing expanded hyperparameter grids -\n")
    expanded_grid <- readRDS(file = expanded_grid_path)
  }
  
  message("- preprocessing refchem manifest -\n")
  collapsed_targets <- collapse_refchemdb_targets(refchemdb_path = refchemdb_path,
                                                  support_levels = c(support_level),
                                                  min_chemicals = min_chemicals,
                                                  cutree_h = 0.7,
                                                  cluster_method= "complete")
  
  target_annotations <- collapsed_targets$collapsed_targets
  target_annotations <- target_annotations[target_annotations$support >= support_level,]
  
  if(one_target_to_chems == TRUE){
    stingy_target_annotations <- data.frame()
    for (i in unique(target_annotations$dsstox_substance_id)){
      relevant_targets <- target_annotations[target_annotations$dsstox_substance_id == i,]
      if(nrow(relevant_targets) > 0){
        relevant_targets <- relevant_targets[order(relevant_targets$support, decreasing = TRUE),]
        stingy_target_annotations <- rbind(head(relevant_targets, 1), stingy_target_annotations)
      }
    }
    target_annotations <- stingy_target_annotations
    rm(stingy_target_annotations)
  }
  
  message("- tabulating preprocessed targets -\n")
  target_table <- table_targets(target_annotations)
  
  message("- importing HTTr metadata -\n")
  metadata <- readRDS(metadata_path)
  metadata <- metadata[metadata$dtxsid %in% target_annotations$dsstox_substance_id,]
  
  message("- Selecting Bioactive HTTr metadata -\n")
  tpod_estimates <- read.csv(tpod_estimate_path, header = TRUE)
  metadata <- merge(metadata, tpod_estimates[c("chem_id", "gene_bpac05")], by = "chem_id")
  metadata <- metadata[metadata$conc > metadata$gene_bpac05,]
  
  message("- importing relevant HTTr expression data -\n")
  nested_data <- get_gene_expression_data( metadata = metadata,
                                           gene_expression_data_path = gene_expression_data_path, 
                                           seed = seed,
                                           profile_limit = profile_limit,
                                           probe_info_subset = probe_info_subset)
  
  message("- tabulating available HTTr profiles -\n")
  profile_table <- table_profiles(target_table = target_table, 
                                  metadata = nested_data$metadata, 
                                  target_annotations = target_annotations,
                                  min_chemicals = min_chemicals,
                                  min_profiles = min_profiles)
  
  message("- identifying top reference chemicals for tabulated targets -\n")
  exemplar_chems <- get_exemplar_chems(target_annotations = target_annotations,
                                       metadata = nested_data$metadata,
                                       profile_table = profile_table,
                                       min_chemicals = min_chemicals,
                                       min_profiles = min_profiles,
                                       target_table = target_table)
  
  message("- re-tabulating HTTr profiles excluding exemplar reference chemicals -\n")
  profile_table <- table_profiles(target_table = target_table, 
                                  metadata = nested_data$metadata, 
                                  target_annotations = target_annotations,
                                  min_chemicals = min_chemicals,
                                  min_profiles = min_profiles,
                                  exemplar_chems = exemplar_chems)
  
  #flips the order in which MIEs are modeled - useful if you had to kill a job halfway through and want to restart the job working from the other end of the table
  profile_table <- profile_table[order(profile_table$n_profiles, decreasing = TRUE),]
  
  if(reverse_MIE_training_order == TRUE){
    profile_table <- profile_table[order(profile_table$n_profiles, decreasing = FALSE),]
  }
  
  if (!is.null(previous_analysis_path)){
    already_run_MIEs <- list.files(path = previous_analysis_path)
    profile_table <- profile_table[profile_table$target_mode %notin% already_run_MIEs,]
  }
  
  message(paste0("- training models for ", length(profile_table$target_mode), " MIE targets with ", length(model_names)," algorithms -\n"))
  
  #modeling_result <-model_targets(profile_table = profile_table, 
  modeling_result <- model_targets(profile_table = profile_table, 
                                   expanded_grid = expanded_grid,
                                   target_workers = target_workers,
                                   null_workers = null_workers,
                                   allowParallel_training = allowParallel_training,
                                   n_nulls = n_nulls,
                                   model_names = model_names, 
                                   support_level = support_level,
                                   nested_data = nested_data,
                                   target_annotations = target_annotations,
                                   seed = seed, 
                                   exemplar_chems = exemplar_chems,
                                   save_model = save_model,
                                   output_dir = output_dir,
                                   focused_analysis_path = focused_analysis_path,
                                   critical_perm_metrics,
                                   critical_perm_thresholds)
  
  # output = list("profile_table" = profile_table,
  #               "modeling_result" =  modeling_result)
  # 
  # output = list.append(output, "jaccard_matrix" = collapsed_targets$jaccard_matrix)
  # output = list.append(output, "groups" = collapsed_targets$groups)
  #return(output)
}



# summarize_results_from_files - reads in structured result files from ml_job or ml_analysis and generates a summary
#
# Parameters:
#  analysis_folder (character) = full path to analysis folder containing result files broken down by MIE
#
# Return Value:
#  (data.frame) = data frame summarizing the performance statistics from MIE models

summarize_results_from_files <- function(analysis_folder){
  require(stringr)
  require(plyr)
  #initialize catcher variable
  catcher = data.frame()
  analysis_folder_counter = 0
  #iterate through analysis folders - one per param configuration
  mie_counter = 0
  #generate a list of files corresponding to all the MIEs modeled
  MIE_names <- list.files(path = analysis_folder)
  MIE_paths <- list.files(path = analysis_folder, full.names = TRUE)
  #iterate through each MIE folder
  for (i in 1:length(MIE_names)){
    MIE_name <- MIE_names[i]
    MIE_path <- MIE_paths[i]
    mie_counter = mie_counter + 1
    message("reading from mie folder ", mie_counter, " of ", length(MIE_names))
    #generate a list of models run for this MIE - take care to exclude the permutation results, if present
    model_files <- list.files(path = MIE_path)
    permutation_file <- grep(paste0("permutation", collapse = "|"), model_files, invert = FALSE, value = TRUE)
    model_files <- grep(paste0("permutation", collapse = "|"), model_files, invert = TRUE, value = TRUE)
    model_result_catcher <- data.frame()
    for(model_file in model_files){
      #model_file = model_files[1]
      temp_input_object <- readRDS(paste0(MIE_path, "/", model_file))
      
      #add number of chemical targets to each summary before output
      derp <- temp_input_object$model$metadata[temp_input_object$model$metadata$use == "train",]
      derp <- derp[derp$label == "target",]
      temp_input_object$summary$chemical_targets <- length(unique(derp$dtxsid))
      temp_input_object$summary$model_path <- paste0(MIE_path, "/", model_file)
      
      model_result_catcher <- rbind(model_result_catcher, temp_input_object$summary)
      gc()
    }
    if(length(permutation_file) > 0){
      temp_permutation_object <- readRDS(paste0(MIE_path, "/", permutation_file))
      temp_permutation_object$permutation_summary = temp_permutation_object$permutation_summary[order(temp_permutation_object$permutation_summary$model_name, decreasing = TRUE),]
      model_result_catcher <- model_result_catcher[order(model_result_catcher$model_name, decreasing = TRUE),]
      model_result_catcher <- cbind(model_result_catcher, temp_permutation_object$permutation_summary[setdiff(names(temp_permutation_object$permutation_summary), names(model_result_catcher))])
      model_result_catcher$permutation_path <- paste0(MIE_path, "/", permutation_file)
      perm_table <- data.frame(table(temp_permutation_object$permutation_source_data$summary_output$model_name))
      names(perm_table) <- c("model_name", "n_nulls")
      model_result_catcher <- merge(model_result_catcher, perm_table, by = "model_name")
    }
    catcher <- rbind.fill(catcher, model_result_catcher)
  }
  return(catcher)
}



# generate_MIE_predictions - generates MIE predictions from saved models
#
# Parameters:
#  high_performance_models (data.frame) = data frame containing model names and full paths
#  metadata_path (character) = full path to file containing metadata for httr study
#  gene_expression_data_path (character) = full path to file containing normalized gene expression data
#  exemplar_chems (data.frame) = data frame containing exemplar chemical information
#  target_annotations (data.frame) = cleaned and filtered refchemDB object
#  probe_info_subset_path (character) = optional full path to file containing probe ids to subset gene expression data down to
#
# Return Value:
#  (data.frame) = data frame containing MIE predictions for each classifier in high_performance_models

generate_MIE_predictions <- function(high_performance_models,
                                     metadata_path,
                                     gene_expression_data_path,
                                     exemplar_chems, 
                                     target_annotations,
                                     probe_info_subset_path = NULL){
  #define notin function
  `%notin%` <- Negate(`%in%`)
  
  #if probe_info_subset_path is defined, subset probes down to the probes in that path
  if(!is.null(probe_info_subset_path)){
    library(readxl)
    probe_info_subset <- read_xlsx(path = probe_info_subset_path)
    names(probe_info_subset)[1] <- "probe_name"
  } else {
    probe_info_subset <- NULL
  }
  
  message("- importing HTTr metadata -\n")
  metadata <- readRDS(metadata_path)
  
  message("- importing relevant HTTr expression data -\n")
  
  nested_data <- get_gene_expression_data(metadata = metadata,
                                          gene_expression_data_path = gene_expression_data_path,
                                          probe_info_subset = probe_info_subset)
  
  
  nested_data$metadata[is.na(nested_data$metadata$dtxsid),]$dtxsid <- nested_data$metadata[is.na(nested_data$metadata$dtxsid),]$trt_name
  
  catcher = data.frame()
  
  message(" - Iterating Through Saved Models to Generate Predictions - ")
  
  #iterate through each model
  for (i in 1:nrow(high_performance_models)){
    message("generating predictions using ", high_performance_models[i,]$target_name, " with ", high_performance_models[i,]$model_name, " (",i," of ", nrow(high_performance_models), ")")
    current_model <- readRDS(file = high_performance_models[i,]$model_path)
    predictions <- data.frame(predict(current_model$model , newdata = nested_data$gene_expression_data, type = "prob"))
    
    predictions$sample_id <- row.names(nested_data$gene_expression_data)
    predictions$null <- NULL
    
    current_metadata <- current_model$model$metadata
    
    #generate flags for samples linked to chemicals that were used in training
    MIE_active_DTXSIDs <- unique(current_metadata[current_metadata$use == "train" & current_metadata$label == "target",]$dtxsid)
    
    MIE_active_training_samples <- nested_data$metadata[nested_data$metadata$dtxsid %in% MIE_active_DTXSIDs,]$sample_id
    
    predictions$is_MIE_active_training_chem <- 0
    if (length(MIE_active_training_samples) != 0){
      predictions[predictions$sample_id %in% MIE_active_training_samples,]$is_MIE_active_training_chem <- 1
    }
    
    MIE_inactive_DTXSIDs <- unique(current_metadata[current_metadata$use == "train" & current_metadata$label == "null",]$dtxsid)
    
    MIE_inactive_training_samples <- current_metadata[current_metadata$use == "train" & current_metadata$label == "null",]$sample_id
    
    predictions$is_MIE_inactive_training_chem <- 0
    if (length(MIE_inactive_training_samples) != 0){
      predictions[predictions$sample_id %in% MIE_inactive_training_samples,]$is_MIE_inactive_training_chem <- 1
    }
    
    current_exemplar <- exemplar_chems[exemplar_chems$target_mode == current_model$summary$target_name,]$dsstox_substance_id
    
    samples_linked_to_MIE_exemplar_chem <- na.omit(nested_data$metadata[nested_data$metadata$dtxsid == current_exemplar,]$sample_id)
    
    predictions$exemplar_chemical_for_MIE <- 0
    
    if (length(samples_linked_to_MIE_exemplar_chem) != 0){
      predictions[predictions$sample_id %in% samples_linked_to_MIE_exemplar_chem,]$exemplar_chemical_for_MIE <- 1
    }
    
    matcher <- subset(nested_data$metadata, select = c("chem_id", "sample_id", "stype", "plate_id", "block_id", "pg_id", "conc", "dose_level", "chem_name", "dtxsid"))
    
    matcher <- merge(matcher, predictions, by="sample_id")
    
    colnames(matcher)[which(names(matcher) == "target")] <- "pred"
    matcher$target_name <- current_model$summary$target_name
    matcher$model_name <- current_model$summary$model_name
    
    #generate a flag for whether a chemical is associated with the MIE regardless of whether it was used in training
    matcher$MIE_linkage_support_level <- 0
    
    DTXSIDS_linked_to_MIE <- matcher[matcher$dtxsid %in% target_annotations[target_annotations$target_mode == current_model$summary$target_name,]$dsstox_substance_id,]$dtxsid
    
    if (length(DTXSIDS_linked_to_MIE) != 0){
      for (chem in DTXSIDS_linked_to_MIE){
        matcher[matcher$dtxsid == chem & !is.na(matcher$dtxsid),]$MIE_linkage_support_level <- target_annotations[target_annotations$target_mode == current_model$summary$target_name & target_annotations$dsstox_substance_id == chem,]$support[1] 
      }
    }
    catcher = rbind(matcher, catcher)
  }
  return(catcher)
}



# calculate_tpods - generates MIE predictions from saved models
#
# Parameters:
#  gene_cr_file_path (character) = full path to httrpathway result file from gene level concentration response analysis
#
# Return Value:
#  (data.frame) = data frame containing 5th percentile gene level BMDs to be used as a transcriptomic point of departure

calculate_tpods <- function(gene_cr_file_path) {
  
  library(data.table)  
  library(stringr)
  
  #define simple functions for extracting the highest and lowest tested concentrations from typical tcplfit2 outputs
  fun_high <- function(x) {
    max(as.numeric(unlist(str_split(string = x, pattern = "[|]"))))
  }
  fun_low <- function(x) {
    min(as.numeric(unlist(str_split(string = x, pattern = "[|]"))))
  }
  
  message("- Loading Gene Level Data -\n")  
  
  # first load gene level data and filter
  load(gene_cr_file_path)
  
  # before any filtering, get a vector of all sample ids represented in this file
  all_sample_ids_in_gene_file <- unique(GENE_CR$sample_id)
  
  # drop genes that fail hitcall or ToC thresholds
  GENE_CR <- GENE_CR[GENE_CR$hitcall >= 0.9 & GENE_CR$top_over_cutoff >= 1,]
  
  # coerce to data.table
  GENE_CR <- data.table(GENE_CR)
  
  # drop entries with NA in hitcall or bmd
  GENE_CR <- GENE_CR[!is.na(GENE_CR$hitcall),]
  GENE_CR <- GENE_CR[!is.na(GENE_CR$bmd),]
  
  # parse the highest tested concentration used in curve fitting from the conc field
  GENE_CR$highest_conc <- unlist(lapply(GENE_CR$conc, fun_high))
  
  # drop retain genes only if their BMD was not higher than the highest tested conc
  GENE_CR <- GENE_CR[bmd <= highest_conc,]
  
  #extract the lowest tested concentration
  #if a gene has a bmd that is extrapolated to 10X lower than the lowest tested conc, set that gene bmd to 10X lower than the lowest tested conc
  GENE_CR$lowest_conc <- unlist(lapply(GENE_CR$conc, fun_low))
  GENE_CR[bmd < (lowest_conc/10),]$bmd <- GENE_CR[bmd < (lowest_conc/10),]$lowest_conc/10
  
  by_sample_summary <- data.frame()
  
  #step through each sample and calculate summary values
  for (temp_sample in all_sample_ids_in_gene_file){
    
    #subset gene level data to just this sample
    by_sample_gene_data <- GENE_CR[na.omit(sample_id == temp_sample),]
    
    #if no gene data are available, use in placeholder values - alternatively, calculate bpac05 and n active genes
    if (nrow(by_sample_gene_data) == 0){
      gene_bpac05 = 1000
      gene_bpacM = 1000
      n_active_genes = 0
    } else {
      gene_bpac05 = quantile(by_sample_gene_data$bmd, probs = 0.05, na.rm = TRUE)
      gene_bpacM = median(by_sample_gene_data$bmd, na.rm = TRUE)
      n_active_genes = nrow(by_sample_gene_data)
    }
    
    # add data for this chemical to the growing by_sample_summary dataframe
    by_sample_summary <- rbind(data.frame("chem_id" = temp_sample,
                                          "gene_bpac05" = gene_bpac05, 
                                          "gene_bpacM" = gene_bpacM, 
                                          "n_active_genes" =n_active_genes), 
                               by_sample_summary)
    
  }
  return(by_sample_summary)
}



# make_annotations_pretty - simple helper function that makes refchemdb target_mode annotations more human readable
#
# Parameters:
#  annotations (vector) = character vector of refchemdb target_mode annotations
#
# Return Value:
#  (vector) = character vector of more human readable refchemdb annotations


make_annotations_pretty <- function(annotations){
  annotations <- gsub(x = annotations, pattern = "_Positive", replacement = " Agonism")
  annotations <- gsub(x = annotations, pattern = "_Negative", replacement = " Antagonism")
  annotations <- gsub(x = annotations, pattern = "_group", replacement = "")
  annotations
}



